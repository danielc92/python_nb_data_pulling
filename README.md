# Web Scraping with Python
This repo contains multiple `jupyter` notebook files, with a focus on web scraping using the `requests`, `bs4` and `pandas` libraries.

This project has a diverse range of websites;
- university
- quotes
- bookstore
- movies database
- home grants 
- csv data
- api stocks
- speeding camera locations
- nobel prizes

# Before you get started
Concepts you should understand before getting into this project;
- Web scraping
- HTTP requests
- Basic python skills
- Running jupyter notebooks (optional)
- XML/HTML structure

# Setup
**How to obtain this repository:**
```sh
git clone https://github.com/danielc92/python_nb_data_pulling.git
```
**Modules/dependencies:**
- `pandas`
- `requests`
- `jupyter`
- `bs4`

Install the following dependences:
```sh
cd /local/location/of/this/repo
pip install pandas jupyter requests bs4
```

# Tests
- Succesfully pulled data from ~dozen websites
- Storing data pulled into local files
- Pulling from highly hierarchical website structures

# Contributors
- Daniel Corcoran

# Sources
- [bs4 documentation](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)
- [requests documentation](http://docs.python-requests.org/en/master/)